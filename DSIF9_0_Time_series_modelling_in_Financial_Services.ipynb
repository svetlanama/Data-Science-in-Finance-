{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svetlanama/Data-Science-in-Finance-/blob/main/DSIF9_0_Time_series_modelling_in_Financial_Services.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH1XQ07F5Bx8"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "\n",
        "## Agenda:\n",
        "1. Time series data prep\n",
        "2. Time series decomposition\n",
        "3. Forecasting methods and model families\n",
        "\n",
        "\n",
        "Demo: Implementation in Python\n",
        "------------------------------\n",
        "\n",
        "### LendingClub Use Case\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2E8b6UKTOxP"
      },
      "source": [
        "### Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxe4AQC2TOxP"
      },
      "source": [
        "#### User-specified parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9rZwP44TOxQ"
      },
      "outputs": [],
      "source": [
        "python_material_folder_name = \"python-material\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrSMEJnLTOxR"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAmnqEe1TOxR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "# Check if in Google Colab environment\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    # Mount drive\n",
        "    drive.mount('/content/drive')\n",
        "    # Set up path to Python material parent folder\n",
        "    path_python_material = rf\"drive/MyDrive/{python_material_folder_name}\"\n",
        "        # If unsure, print current directory path by executing the following in a new cell:\n",
        "        # !pwd\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    # If working locally on Jupyter Notebook, parent folder is one folder up (assuming you are using the folder structure shared at the beginning of the course)\n",
        "    path_python_material = \"..\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huxa6nWcTOxR"
      },
      "source": [
        "# Import data\n",
        "This time, we will be retrieving Apple's stock prices using an API with the yfinance library, a popular wrapper around Yahoo Finance's public APIs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKm1VuzyTOxS"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "# Define the ticker symbol for Apple Inc.\n",
        "chosen_stock = 'AAPL'\n",
        "\n",
        "# Use yfinance to download the stock data\n",
        "stock_data = yf.download(chosen_stock, start='2015-01-01', end='2025-03-06', interval='1d')\n",
        "\n",
        "# Display the first few rows of the data\n",
        "stock_data.tail()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPeDt8wTJbkG"
      },
      "outputs": [],
      "source": [
        "stock_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XWNbYKpJbkG"
      },
      "source": [
        "Let's plot the time series:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ2RFbIMTOxT"
      },
      "outputs": [],
      "source": [
        "def plot_stock_price(stock_data, ticker):\n",
        "\n",
        "     # Plot the closing price data\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(stock_data['Close'], label=f\"{ticker} closing price\")\n",
        "    plt.title(f\"{ticker} closing prices\")\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Price (USD)')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_stock_price(stock_data, chosen_stock)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m2Oi6E_TOxU"
      },
      "source": [
        "# 1. Time series data prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X3SrXbeTOxU"
      },
      "outputs": [],
      "source": [
        "# Ensure the index is a DatetimeIndex\n",
        "stock_data.index = pd.to_datetime(stock_data.index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CY-86dPEJbkG"
      },
      "outputs": [],
      "source": [
        "# Set the frequency of the time series to 'B' (business day)\n",
        "stock_data = stock_data.asfreq('B')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjFWO_YTJbkG"
      },
      "source": [
        "### Check for null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHQjjBVfJbkG"
      },
      "outputs": [],
      "source": [
        "nas = stock_data['Close'].isna().sum()[0]\n",
        "print(f\"Null values: {nas} \\n \\n\")\n",
        "\n",
        "if nas > 0:\n",
        "    print(\"Example NAs (head):\")\n",
        "    print(stock_data[stock_data['Close'].isna()].head(1))\n",
        "    print(\"Example NAs (tail):\")\n",
        "    print(stock_data[stock_data['Close'].isna()].tail(1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZrpuUgWJbkH"
      },
      "outputs": [],
      "source": [
        "plot_stock_price(stock_data.tail(30), chosen_stock)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "L5mjRKPGJbkH"
      },
      "outputs": [],
      "source": [
        "## Forward fill to handle missing data points (optional, depending on the data)\n",
        "stock_data['Close'] = stock_data['Close'].ffill()\n",
        "\n",
        "nas = stock_data['Close'].isna().sum()\n",
        "print(f\"Null values: {nas} \\n \\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-rgMv5nJbkH"
      },
      "outputs": [],
      "source": [
        "stock_data['Close'].tail(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKslZGoCJbkH"
      },
      "source": [
        "Note: We would want to capture information on which data points were originally null, and also methodology used to fill them.  \n",
        "For mor methods for dealing with missing values in time-series data, see [here](https://www.geeksforgeeks.org/how-to-deal-with-missing-values-in-a-timeseries-in-python/?ref=ml_lbp).  \n",
        "Other useful link [here](https://gking.harvard.edu/files/pr.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE0jfRfdJbkH"
      },
      "source": [
        "### Are weekends included?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ily7MO6wJbkH"
      },
      "outputs": [],
      "source": [
        "weekends = stock_data.index[stock_data.index.weekday >= 5]\n",
        "\n",
        "if len(weekends) > 0:\n",
        "    print(\"Weekends are included in the time series.\")\n",
        "    print(weekends)  # Optionally print which dates are weekends\n",
        "else:\n",
        "    print(\"No weekends are included in the time series.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFvYio2kJbkH"
      },
      "source": [
        "# 2. Time series decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmNEPhv8JbkH"
      },
      "source": [
        "**Time series decomposition** is the process of breaking down a time series into its fundamental components:\n",
        "- **Trend**: The long-term movement in the data. For instance, an upward or downward trend in stock prices.\n",
        "- **Seasonality**: Short-term, regular variations in data, often tied to calendar seasons or other recurring events.\n",
        "- **Residuals (Noise)**: The random variation that is not explained by the trend or seasonality.\n",
        "\n",
        "This helps in understanding the underlying patterns in the data and is useful for forecasting and analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad-UqKm0JbkH"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# Let's bring back the plot\n",
        "plot_stock_price(stock_data, chosen_stock)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prhCwwsSJbkH"
      },
      "source": [
        "### Additive vs. Multiplicative time series\n",
        "If the magnitude of seasonal fluctuations increases as the trend increases, the series likely follows a multiplicative model.   \n",
        "If the seasonal variations remain roughly constant, the series is likely additive.  \n",
        "\n",
        "### <span style=\"color:BLUE\"> **>>> DISCUSSION:**  </span>    \n",
        "> What do you think is true in this case?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc1Aao-9TOxU"
      },
      "outputs": [],
      "source": [
        "# Decompose the time series (using 'Adj Close' prices)\n",
        "decomposition = seasonal_decompose(stock_data['Close']\n",
        "                                   , model='multiplicative'\n",
        "                                   , period=252)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAjIY1SVJbkH"
      },
      "source": [
        "The number 252 is commonly used in financial data analysis to represent the number of trading days in a year because stock markets are usually open for about 252 days annually (excluding weekends and holidays).\n",
        "\n",
        "By setting period=252, you are telling the decomposition to detect seasonal patterns that repeat roughly every 252 trading days, i.e., annually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mazf9gm2JbkH"
      },
      "source": [
        "### Extrapolating components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZQJfbjUJbkH"
      },
      "outputs": [],
      "source": [
        "# Extract components\n",
        "trend = decomposition.trend\n",
        "seasonal = decomposition.seasonal\n",
        "residual = decomposition.resid\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GxQ-iRZTOxV"
      },
      "outputs": [],
      "source": [
        "# Plot the decomposition\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.subplot(4,1,1)\n",
        "plt.plot(stock_data['Close'], label='Original')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.subplot(4,1,2)\n",
        "plt.plot(trend, label='Trend')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.subplot(4,1,3)\n",
        "plt.plot(seasonal, label='Seasonality')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.subplot(4,1,4)\n",
        "plt.plot(residual, label='Residuals')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA2mCIqeJbkH"
      },
      "source": [
        "### First glance interpretation\n",
        "\n",
        "### <span style=\"color:BLUE\"> **>>> DISCUSSION:**  </span>    \n",
        "> What can we observe in the time series?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbXs3LOhJbkH"
      },
      "source": [
        "____________\n",
        "\n",
        "Hypothesis: seasonal spike detected in relation to Apple's Development Conference in September?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hGSYSHkTOxV"
      },
      "outputs": [],
      "source": [
        "# Highlight iPhone release period (September)\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(seasonal, label='Seasonality')\n",
        "for year in range(2015, 2024):\n",
        "    plt.axvspan(f'{year}-09-01', f'{year}-09-30'\n",
        "                , color='blue'\n",
        "                , alpha=0.3\n",
        "                , label='iPhone Release (Sept)' if year == 2015 else \"\")\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.title('Apple ptock price seasonality with iPhone release period highlighted')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_WEu4APJbkI"
      },
      "source": [
        "Let's look at actual prices.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktX6roK9JbkI"
      },
      "outputs": [],
      "source": [
        "# Highlight iPhone release period September\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(stock_data['Close'], label='Original')\n",
        "\n",
        "# Highlight and September\n",
        "for year in range(2015, 2024):\n",
        "        plt.axvspan(f'{year}-09-01', f'{year}-09-30'\n",
        "                , color='blue'\n",
        "                , alpha=0.3\n",
        "                , label='iPhone Release (Sept)' if year == 2015 else \"\")\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.title('Apple ptock price with iPhone release highlighted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvBbIMEkTOxV"
      },
      "source": [
        "### Explaining decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5b4ICh1TOxW"
      },
      "source": [
        "#### 1\\. **Additive Decomposition**\n",
        "\n",
        "In the **additive** model, the time series is assumed to be the sum of its components:\n",
        "\n",
        "Y(t) = T(t) + S(t) + R(t)\n",
        "\n",
        "It's appropriate when the seasonality does not vary with the level of the time series (e.g., if the seasonal effect is a constant absolute amount).\n",
        "E.g.: If sales increase by $1000 every December regardless of the overall trend (whether the company is growing or shrinking), then an additive model might be suitable.\n",
        "\n",
        "#### 2\\. **Multiplicative Decomposition**\n",
        "\n",
        "In the **multiplicative** model, the time series is assumed to be the product of its components:\n",
        "\n",
        "Y(t)= T(t) × S(t) × R(t)\n",
        "\n",
        "It's appropriate when the seasonality varies proportionally with the level of the time series (e.g., if the seasonal effect is a percentage of the trend).\n",
        "E.g.: Sales triple every December compared to other months. If the overall sales are increasing, the seasonal effect (December sales spike) also increases proportionally.\n",
        "\n",
        "In the multiplicative case, notice how the seasonal component's magnitude varies with the level of the trend. This makes the multiplicative model more appropriate when the seasonal effect is proportional to the trend level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSvlC7AVTOxV"
      },
      "outputs": [],
      "source": [
        "def decom_report(decomposition_df, date):\n",
        "\n",
        "    actual = decomposition.observed[date]\n",
        "    trend = decomposition.trend[date]\n",
        "    seasonal = decomposition.seasonal[date]\n",
        "    residual = decomposition.resid[date]\n",
        "    print(f\"\"\"\n",
        "        Actual: {actual}\n",
        "        Trend: {trend}\n",
        "        Seasonal: {seasonal}\n",
        "        Residual: {residual}\n",
        "        \"\"\"\n",
        "        )\n",
        "    if actual == trend + seasonal + residual:\n",
        "        print(f\"Model type is additive\")\n",
        "    elif actual == trend * seasonal * residual:\n",
        "        print(f\"Model type is multiplicative\")\n",
        "    else:\n",
        "        print(f\"Something is not adding up..\")\n",
        "\n",
        "decom_report(decomposition, \"2024-01-22\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESeNw5I9JbkM"
      },
      "source": [
        "## Use cases for decomposition\n",
        "\n",
        "| **Use Case**                   | **Description**                                                                                                                                 |\n",
        "|---------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **Trend Identification**        | Detect long-term movements in stock prices or economic indicators, helping analysts forecast future market behavior by understanding underlying trends. |\n",
        "| **Seasonality Detection**       | Uncover repeating cycles in financial data, such as quarterly earnings or monthly sales, improving forecast accuracy by adjusting for seasonal effects. |\n",
        "| **Anomaly Detection**           | Isolate irregular spikes or dips in financial transactions or asset prices (e.g., potential fraud or market shocks) to enhance the robustness of forecasting models. |\n",
        "| **Demand Forecasting**          | Decompose historical demand data for financial products (e.g., loans, insurance) to predict future trends and optimize product offerings and pricing strategies. |\n",
        "| **Financial Market Analysis**   | Reveal cyclical behavior and seasonality in stock prices or trading volumes, aiding traders in making informed decisions based on expected market movements. |\n",
        "| **Risk Assessment**             | Analyze historical price data to identify trends and seasonal patterns, helping financial institutions assess risks and model potential future volatility. |\n",
        "| **Portfolio Management**        | Use decomposition to identify long-term trends and seasonal patterns in asset returns, improving asset allocation strategies and risk management. |\n",
        "| **Credit Risk Modeling**        | Improve credit risk assessments by decomposing loan default rates into trend and seasonal components, leading to more accurate predictions of borrower behavior. |\n",
        "| **Economic Indicator Forecasting** | Forecast economic indicators (e.g., GDP growth rates, inflation) by identifying underlying trends and seasonal cycles, supporting better macroeconomic planning. |\n",
        "| **Investment Strategy Optimization** | Enhance investment strategies by understanding the seasonal patterns in asset classes, allowing for better timing of buy/sell decisions based on historical data. |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAPWQ0QOTOxW"
      },
      "source": [
        "# 3. Forecasting methods and model families\n",
        "-------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HpMwLpEJbkM"
      },
      "source": [
        "| **Method** | **Quick Description** | **Pros** | **Cons** |\n",
        "| --- | --- | --- | --- |\n",
        "| **Moving Average** | smooths a time series by averaging data points within a sliding window. |- Simple to implement; Easy to understand | Not suitable for trends or seasonality; Can lag behind actual data |\n",
        "| **Exponential Smoothing** | A technique that applies decreasing weights to past observations, giving more importance to recent data. | Simple and intuitive ; Adaptable to data with trends and seasonality; Good for short-term forecasts | Requires parameter tuning;  Less effective with complex patterns |\n",
        "| **ARIMA (AutoRegressive Integrated Moving Average)** | A model that combines autoregressive, differencing, and moving average components to handle stationary time series data. | Can model complex relationships;  Flexible and widely used;  Handles various patterns well | Assumes stationarity (data needs to be transformed); Requires careful parameter tuning |\n",
        "| **Deep Learning Based** | Uses advanced neural network architectures (e.g., LSTM, RNN) to capture complex patterns and dependencies in time series data. | Can model complex patterns and nonlinear relationships;  Effective for long-term forecasting;  Handles multiple variables | Computationally intensive;  Requires large datasets;  Complex to implement and interpret |\n",
        "| **Prophet** | A forecasting tool by Facebook that uses additive or multiplicative models to handle trends, seasonality, and holidays. | Handles missing data and outliers well;  Simple to use and interpret;  Includes holiday effects and seasonality | Less effective with highly irregular data; Assumes a specific trend model |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzBxI9JAJbkM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "def train_test_split_temporal(data, test_size=30):\n",
        "    train = data[:-test_size]\n",
        "    test = data[-test_size:]\n",
        "    return train, test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBlpKdgOJbkM"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split_temporal(stock_data['Close'] # 2 years and a month of data\n",
        "                                       , 30 # of which one month in test set\n",
        "                                       )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15Pw-es-JbkM"
      },
      "source": [
        "## 3.1 Moving Averages\n",
        "\n",
        "A **Moving Average** smooths out time series data by averaging data points within a sliding window. This helps in identifying the trend by filtering out the noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U7zD6chJbkM"
      },
      "outputs": [],
      "source": [
        "def forecast_moving_average(train_data, window=20, forecast_horizon=30, frequency = 'B'):\n",
        "    \"\"\"\n",
        "    Generate forecasts based on a rolling window moving average.\n",
        "\n",
        "    Parameters:\n",
        "    train_data (pd.Series): Training data.\n",
        "    window (int): The window size for the moving average.\n",
        "    forecast_horizon (int): Number of days to forecast into the future.\n",
        "\n",
        "    Returns:\n",
        "    pd.Series: Forecasted values\n",
        "    \"\"\"\n",
        "    moving_avg = train_data.rolling(window=window).mean()  # 20-day moving average\n",
        "\n",
        "    # Create a forecast for the next 'forecast_horizon' days\n",
        "    last_moving_avg_value = moving_avg.iloc[-1]  # Get the last moving average value\n",
        "    forecast_index = pd.date_range(start=train_data.index[-1] + pd.Timedelta(days=1),\n",
        "                                    periods=forecast_horizon, freq=frequency)  # Business days\n",
        "    forecast_values = pd.Series([last_moving_avg_value] * forecast_horizon, index=forecast_index)  # Extend the last value\n",
        "\n",
        "\n",
        "\n",
        "    return forecast_values\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utbR0FwvJbkM"
      },
      "outputs": [],
      "source": [
        "ma = forecast_moving_average(train)\n",
        "ma[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJHTCaRfJbkM"
      },
      "outputs": [],
      "source": [
        "def plot_actuals_vs_forecasts(train_data, test_data, forecasts, title='Actuals vs Forecasts'):\n",
        "    \"\"\"\n",
        "    Plot actual values against forecasted values and print error metrics.\n",
        "\n",
        "    Parameters:\n",
        "    train_data (pd.Series): Training values.\n",
        "    test_data (pd.Series): Testing values.\n",
        "    forecasts (pd.Series): Forecasted values.\n",
        "    title (str): Title of the plot.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(train_data.index, train_data, label='Train Data', color='blue')\n",
        "    plt.plot(test_data.index, test_data, label='Test Data', color='orange')\n",
        "    plt.plot(forecasts.index, forecasts, label='Forecasts', color='green', linestyle='--')\n",
        "    plt.axvline(x=test_data.index[0], color='red', linestyle='--', label='Forecast Start')\n",
        "    plt.legend(loc='best')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Price (USD)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate and print error metrics\n",
        "    mae = mean_absolute_error(test_data, forecasts)\n",
        "    rmse = np.sqrt(mean_squared_error(test_data, forecasts))\n",
        "\n",
        "    print(f'Mean Absolute Error (MAE): {mae:.2f}')\n",
        "    print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz4lbEXrJbkM"
      },
      "outputs": [],
      "source": [
        "plot_actuals_vs_forecasts(train.tail(30), test, ma, title=f'{chosen_stock} Actuals vs Forecasts (Moving Average)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPh0rIcNJbkN"
      },
      "source": [
        "### <span style=\"color:BLUE\"> **>>> DISCUSSION:**  </span>    \n",
        "> Do you think this is a good model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzFmn-N8JbkN"
      },
      "outputs": [],
      "source": [
        "# A more realistic approach would be to compute the moving average dynamically as new \"predicted\" values are added.\n",
        "def forecast_moving_average_dynamic(train_data, window=20, forecast_horizon=30, frequency='B'):\n",
        "    \"\"\"\n",
        "    Generate dynamic forecasts based on a rolling window moving average.\n",
        "\n",
        "    Parameters:\n",
        "    train_data (pd.Series): Training data.\n",
        "    window (int): The window size for the moving average.\n",
        "    forecast_horizon (int): Number of days to forecast into the future.\n",
        "    frequency (str): the frequency of the dates.\n",
        "\n",
        "    Returns:\n",
        "    pd.Series: Forecasted values\n",
        "    \"\"\"\n",
        "    forecast_values = []\n",
        "    forecast_index = pd.date_range(start=train_data.index[-1] + pd.Timedelta(days=1),\n",
        "                                    periods=forecast_horizon, freq=frequency)\n",
        "\n",
        "    temp_data = train_data.copy()  # Create a copy to avoid modifying the original data\n",
        "\n",
        "    for i in range(forecast_horizon):\n",
        "        moving_avg = temp_data.rolling(window=window).mean()\n",
        "        last_moving_avg_value = moving_avg.iloc[-1]\n",
        "        forecast_values.append(last_moving_avg_value)\n",
        "\n",
        "        # Update temp_data with the forecasted value\n",
        "        new_index = forecast_index[i]\n",
        "        temp_data = pd.concat([temp_data, pd.Series([last_moving_avg_value], index=[new_index])])\n",
        "\n",
        "    return pd.Series(forecast_values, index=forecast_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuUT4zjBJbkN"
      },
      "outputs": [],
      "source": [
        "ma_dynamic = forecast_moving_average_dynamic(pd.Series(train.AAPL))\n",
        "ma_dynamic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vvwevNeJbkN"
      },
      "outputs": [],
      "source": [
        "plot_actuals_vs_forecasts(train.tail(30), test, ma_dynamic, title=f'{chosen_stock} Actuals vs Forecasts (Moving Average - Dynamic)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyxPTTXgTOxW"
      },
      "source": [
        "## 3.2 Exponential Smoothing\n",
        "\n",
        "**Exponential Smoothing** gives more weight to recent observations while smoothing out the series. This is useful when the latest data points are more indicative of future trends.\n",
        "See more [here](https://machinelearningmastery.com/exponential-smoothing-for-time-series-forecasting-in-python/#:~:text=Exponential%20smoothing%20is%20a%20time,Jenkins%20ARIMA%20family%20of%20methods.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ9fMH27JbkN"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
        "\n",
        "def forecast_exponential_smoothing(train_data, forecast_horizon=30, seasonal=None, seasonal_periods=None, trend='additive', frequency='B'):\n",
        "    \"\"\"\n",
        "    Generate forecasts using exponential smoothing.\n",
        "\n",
        "    Parameters:\n",
        "    train_data (pd.Series): Training data.\n",
        "    forecast_horizon (int): Number of days to forecast into the future.\n",
        "    seasonal (str): Type of seasonal component ('additive' or 'multiplicative').\n",
        "    seasonal_periods (int): Number of periods in a season.\n",
        "    frequency (str): Frequency of the forecast (e.g., 'B' for business days).\n",
        "\n",
        "    Returns:\n",
        "    pd.Series: Forecasted values\n",
        "    \"\"\"\n",
        "    # Fit the model\n",
        "    model = ExponentialSmoothing(train_data\n",
        "                                 , trend=trend\n",
        "                                 , seasonal=seasonal\n",
        "                                 , seasonal_periods=seasonal_periods)\n",
        "    model_fit = model.fit(optimized=True)\n",
        "\n",
        "    # Create a forecast for the next 'forecast_horizon' days\n",
        "    forecast_index = pd.date_range(start=train_data.index[-1] + pd.Timedelta(days=1),\n",
        "                                    periods=forecast_horizon, freq=frequency)  # Business days\n",
        "    forecast_values = model_fit.forecast(forecast_horizon)\n",
        "\n",
        "    # Create a Series with the correct index\n",
        "    forecast_series = pd.Series(forecast_values, index=forecast_index)\n",
        "\n",
        "    return forecast_series\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31BWC1OsJbkN"
      },
      "outputs": [],
      "source": [
        "es = forecast_exponential_smoothing(train, forecast_horizon=30, trend = \"multiplicative\")\n",
        "es[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ-GnUApJbkN"
      },
      "outputs": [],
      "source": [
        "plot_actuals_vs_forecasts(train.tail(30)\n",
        "                          , test\n",
        "                          , es\n",
        "                          , title=f'{chosen_stock} Actuals vs Forecasts (Exponential Smoothing)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "majExeqEJbkN"
      },
      "source": [
        "See more variations including difference between Simple and Holt Winters [here](https://www.statsmodels.org/stable/examples/notebooks/generated/exponential_smoothing.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_wPU4tWTOxX"
      },
      "source": [
        "## 3.3 ARIMA Models\n",
        "**ARIMA (AutoRegressive Integrated Moving Average)** models are popular for forecasting stationary time series.\n",
        "\n",
        "While exponential smoothing models are based on a description of the trend and seasonality in the data, ARIMA models aim to describe the autocorrelations in the data.\n",
        "\n",
        "### What is Autocorrelation?\n",
        "\n",
        "-   **Definition:** Autocorrelation is the correlation of a time series with its own past values. It shows how current values of a series relate to past values at different time lags.\n",
        "-   **Lag:** A lag is the time difference between observations. For example, a lag of 1 means comparing each value with the value from the previous time period.\n",
        "\n",
        "**So what?**\n",
        "Autocorrelation helps in identifying patterns within a time series data, such as seasonality or cyclic behavior. This information is essential for selecting appropriate models and making accurate predictions.\n",
        "\n",
        "\n",
        "### When to Use ARIMA:\n",
        "-   **Stationarity:** ARIMA models assume that the data is stationary. If autocorrelation patterns suggest trends or seasonality, you may need to transform the data (e.g., differencing) to meet this assumption. More on stationarity [here](https://otexts.com/fpp3/stationarity.html).\n",
        "\n",
        "-   **Autocorrelation:** If your time series data shows significant autocorrelation, it suggests that past values can help predict future values, making ARIMA a suitable model.\n",
        "\n",
        "**ARIMA Components:**\n",
        "-   **AR (AutoRegressive):** Uses the relationship between an observation and a number of lagged observations.\n",
        "-   **I (Integrated):** Represents differencing of raw observations to make the time series stationary.\n",
        "-   **MA (Moving Average):** Uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n",
        "\n",
        "\n",
        "#### Example: plotting and interpreting autocorrelation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGcUFXuBJbkN"
      },
      "outputs": [],
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "\n",
        "# Assuming stock_data is your DataFrame with the 'Adj Close' column and a datetime index\n",
        "\n",
        "# Filter the stock data for the last 30 days\n",
        "last_30_days = stock_data.tail(30)[\"Close\"]\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "\n",
        "# Plot the time series\n",
        "ax1.plot(last_30_days.index, last_30_days, label='Adjusted Close Price', color='blue')\n",
        "ax1.set_title('Adjusted Close Price - Last 30 Days')\n",
        "ax1.set_xlabel('Date')\n",
        "ax1.set_ylabel('Price (USD)')\n",
        "ax1.legend()\n",
        "ax1.grid()\n",
        "\n",
        "# Plot the autocorrelation\n",
        "plot_acf(last_30_days, lags=29, ax=ax2)\n",
        "ax2.set_title('Autocorrelation Function (ACF) - Last 30 Days')\n",
        "ax2.set_xlabel('Lags')\n",
        "ax2.set_ylabel('ACF')\n",
        "ax2.grid()\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEkM-rWkJbkN"
      },
      "source": [
        "The ACF plot above shows the correlation of the time series with its own past values (lags).\n",
        "\n",
        "It helps identify whether past values are useful for predicting future values.\n",
        "\n",
        "The **x-axis** represents the lag (how many time periods back you're correlating the current value with), and the y-axis shows the correlation coefficient.\n",
        "\n",
        "For example:\n",
        "-   **Lag 0:** The autocorrelation at lag 0 is always 1 because a series is perfectly correlated with itself.\n",
        "-   **Positive Correlation:** High autocorrelation at a positive lag indicates that the series has a positive relationship with its past values. For instance, high stock price on one day might lead to high price on the following day.\n",
        "-   **Negative Correlation:** Low autocorrelation (close to -1) indicates an inverse relationship.\n",
        "\n",
        "\n",
        "#### What to look out for:\n",
        "- **significant spikes** above the confidence interval bands\n",
        "    - positive spikes indicate a positive correlation with that lag. For example, if the ACF at lag 1 is high, it suggests that today’s price is correlated with yesterday’s price.\n",
        "    - Negative spikes indicate a negative correlation. A significant negative spike could suggest a mean-reverting behavior.\n",
        "\n",
        "- **decay pattern**\n",
        "    - Slow decay (gradually decreasing values) often indicates a non-stationary process, possibly requiring differencing or other transformations.\n",
        "    - Rapid decay (values drop off quickly) suggests that the time series may be stationary or exhibit short-term memory.\n",
        "    - If the ACF drops off to near zero quickly, it indicates that past values have little predictive power for future values after a short period.\n",
        "    \n",
        "- **values alternating between positive and negative correlations**: this pattern suggests a cyclical or seasonal behavior in the data.\n",
        "    -   **Cyclic pattern**: The alternating positive and negative correlations, especially if they repeat periodically, are indicative of a cycle or seasonality. This means that the time series might have regular ups and downs at predictable intervals, with a cycle length roughly equal to the total number of lags showing this pattern.\n",
        "    -   **Only the first ACF is significant (beyond the confidence interval)**:\n",
        "        -   This implies that, after accounting for the cyclical nature, only the first lag (lag 1) has a strong direct correlation with the current value.\n",
        "        -   The subsequent correlations, while showing a pattern, are not statistically significant at a 95% confidence level. This suggests that the cyclical influence may not be very strong after the first lag, or that the confidence intervals include a large amount of noise.\n",
        "\n",
        "\n",
        "#### Practical applications\n",
        "- Forecasting: If the time series shows a clear trend or seasonality, and the ACF shows significant correlations, you can consider using time series models such as ARIMA.\n",
        "- Model Selection: Insights from the ACF can help determine the appropriate order of the autoregressive (AR) and moving average (MA) components in models like ARIMA. More details and step by step guide on how to select parameters can be found [here](https://mlpills.dev/time-series/parameters-selection-in-arima-models/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGcC7PBDJbkN"
      },
      "source": [
        "### Building an ARIMA model for forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzeEOFcWJbkO"
      },
      "source": [
        "Admittedly, interpreting the above Autocorrelation graph can be very hard!\n",
        "\n",
        "Luckily, we have 2 options to build an ARIMA model:\n",
        "- **Option 1 (simpler approach)**:  leverage a python library to automatically build the optimal ARIMA model.\n",
        "- **Option 2 (harder approach)**:  set up your model manually, based on interpretation of ACF plots (as well as stationarity tests and partial autocorrelation plot).\n",
        "\n",
        "In the cells below, we will follow Option 1.   \n",
        "For Option 2, see step by step guide [here (also linked above)](https://mlpills.dev/time-series/parameters-selection-in-arima-models/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USSlo857JbkO"
      },
      "outputs": [],
      "source": [
        "# First, let's check if series is stationary\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "pvalue = adfuller(last_30_days)[1]\n",
        "if pvalue < 0.05:\n",
        "    print('Series is stationary --> d = 1')\n",
        "else:\n",
        "    print('Series is non-stationary --> d > 1')\n",
        "\n",
        "pvalue = adfuller(stock_data[\"Close\"])[1]\n",
        "if pvalue < 0.05:\n",
        "    print('Series is stationary --> d = 1')\n",
        "else:\n",
        "    print('Series is non-stationary --> d > 1')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIpIK5n9JbkO"
      },
      "outputs": [],
      "source": [
        "from pmdarima.arima import auto_arima\n",
        "\n",
        "model_auto = auto_arima(train, max_p=11, max_d=2, max_q=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsntZsJ7JbkO"
      },
      "outputs": [],
      "source": [
        "model_auto.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9g4K6wgJbkO"
      },
      "source": [
        "SARIMAX(0, 1, 0) is a form of the SARIMAX (Seasonal AutoRegressive Integrated Moving Average with eXogenous variables) model.\n",
        "\n",
        "#### **Components**:\n",
        "\n",
        "**p (AutoRegressive order)**  \n",
        "    -   The AR term specifies how many past observations (lags) are used to predict the current observation.  \n",
        "    -   In **(0, 1, 0)**, p = 0, meaning **no autoregressive terms** are included. The model does not use past values to directly predict future values.  \n",
        "\n",
        "**d (Differencing order)**  \n",
        "    -   The differencing term tells us how many times we need to difference the time series to make it stationary. Differencing is used to remove trends or seasonality.  \n",
        "    -   In **(0, 1, 0)**, d = 1, meaning the model applies **first-order differencing**. In simple terms, this means the model uses the **change** between consecutive observations (i.e., the difference between the current value and the previous value) to make predictions.  \n",
        "    -   Differencing helps stabilize the time series by removing any trends, making it easier to model.\n",
        "\n",
        "**q (Moving Average order)**  \n",
        "-   The MA term controls how many past forecast errors are used to predict the current observation.  \n",
        "-   In **(0, 1, 0)**, q = 0, meaning **no moving average terms** are included. The model does not use past forecast errors to make predictions.  \n",
        "\n",
        "**IN SUMMARY**: This model essentially assumes that future values are a function of their previous value plus a constant drift (if any), without relying on past values or errors.\n",
        "\n",
        "This model is useful when your time series shows a random walk-like behavior with no significant autocorrelation structure but possibly a trend. Stock prices or financial metrics that fluctuate randomly but increase or decrease over time are an example for this.  \n",
        "\n",
        "- **No Seasonal Parameters**: The absence of seasonal orders (P, D, Q, and s) in the model specification strongly suggests that auto_arima did not find statistically significant seasonality in your training data.\n",
        "- **Simple Model**: The selected model (0, 1, 0) is a very simple ARIMA model, essentially just a differenced random walk. This often happens when there is very little to no seasonality, or a very weak seasonality.\n",
        "- it makes sense that auto_arima might not find seasonality in Apple stock data, due to lack of fixed seasonal parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKa1_sxZJbkO"
      },
      "outputs": [],
      "source": [
        "arima = model_auto.predict(len(test))\n",
        "\n",
        "plot_actuals_vs_forecasts(train.tail(30)\n",
        "                          , test\n",
        "                          , arima\n",
        "                          , title=f'{chosen_stock} Actuals vs Forecasts (arima)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCNlqWC7VwOJ"
      },
      "source": [
        "### 3.4 Prophet\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zBEOXDjJbkO"
      },
      "source": [
        "*\"Prophet is a forecasting procedure implemented in R and Python. It is fast and provides completely automated forecasts that can be tuned by hand by data scientists and analysts.\"*\n",
        "\n",
        "Find out more [here](https://facebook.github.io/prophet/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awLPfqwJJbkO"
      },
      "outputs": [],
      "source": [
        "from prophet import Prophet\n",
        "\n",
        "# Initialize Prophet model\n",
        "prophet_model = Prophet()\n",
        "\n",
        "# Fit the model\n",
        "train_df = pd.DataFrame(train).reset_index().rename(columns={'Date':'ds', chosen_stock:'y'})\n",
        "prophet_model.fit(train_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKDW9hVCJbkO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqu9TADCJbkO"
      },
      "outputs": [],
      "source": [
        "# Generate forecast on test set\n",
        "test_df = pd.DataFrame(test).reset_index().rename(columns={'Date':'ds', chosen_stock:'y'})\n",
        "prophet = prophet_model.predict(test_df)\n",
        "prophet.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM-B6kKeJbkO"
      },
      "outputs": [],
      "source": [
        "type(prophet[['ds','yhat']]), type(test)\n",
        "\n",
        "t = prophet[['ds','yhat']]\n",
        "t.set_index('ds', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh9ewNATJbkO"
      },
      "outputs": [],
      "source": [
        "plot_actuals_vs_forecasts(train.tail(30)\n",
        "                          , test\n",
        "                          , t[['yhat']].tail(30)\n",
        "                          , title=f'{chosen_stock} Actuals vs Forecasts (Prophet)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uewsysDTOxY"
      },
      "source": [
        "### 3.5 Deep Learning Approaches\n",
        "\n",
        "Deep learning models, such as Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks, can learn intricate patterns, making them suitable for high-dimensional financial data. Unlike traditional methods, they can deal with highly nonlinear patterns.\n",
        "\n",
        "# Optional assignment\n",
        "Follow example implementation [here(Youtube video)](https://www.youtube.com/watch?v=hpfQE0bTeA4) to perform **LSTM Price Movement Predictions For Trading Algorithms**.\n",
        "How does that differ to the approaches seen today?\n",
        "\n",
        "##### Steps and marking criteria:\n",
        "\n",
        "| Category                          | Criteria                                                                                                                              | Points          |\n",
        "| --------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- | --------------- |\n",
        "| Data Preparation                  | Loads the dataset correctly, handles missing values, and prepares time series data for LSTM (e.g., normalization, sequence creation). | 2               |\n",
        "| LSTM Model Implementation         | Implements LSTM based on the provided YouTube example, ensuring correct model architecture and training process.                      | 2               |\n",
        "| Performance Evaluation            | Evaluates model performance using appropriate metrics (e.g., RMSE, accuracy, loss curves) and interprets the results.                 | 2               |\n",
        "| Comparison to Traditional Methods | Clearly explains how the LSTM approach differs from traditional time series forecasting methods (ARIMA, Prophet, etc.).               | 2               |\n",
        "| Code Quality & Documentation      | Code is well-structured, readable, and includes Markdown comments explaining each step.                                               | 1               |\n",
        "| Business/Trading Insights         | Discusses practical implications for trading algorithms, including strengths and weaknesses of LSTM for price prediction.             | 1               |\n",
        "| Extra Analysis (Optional)         | Experiments with hyperparameter tuning, alternative architectures (e.g., GRU), or additional feature engineering. (Bonus)             | (+1)            |\n",
        "|                                   | **Total:**                                                                                                                                | **10 + 1 (max 10)** |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnNsBpWhTOxZ"
      },
      "source": [
        "# End of session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buqonTnUTOxZ"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(filename=f\"{path_python_material}/images/the-end.jpg\", width=500,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bbrWWYiTOxa"
      },
      "outputs": [],
      "source": [
        "# ========================= HOME ASSIGMENT ========================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUKwRuv0JbkP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}